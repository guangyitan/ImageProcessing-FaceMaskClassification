{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Face Detector (Caffe Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = os.getcwd()+r\"\\deploy.prototxt\"\n",
    "weightsPath = os.getcwd()+ r\"\\res10_300x300_ssd_iter_140000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained Face Mask Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(os.getcwd()+r\"/Trained_Models/mobileNetV2_facemaskmodel\")\n",
    "model = load_model(os.getcwd()+r\"/Trained_Models/DenseNet169/Saved_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are taking its height and width only not taking its channel (RGB)\n",
    "# image = cv2.imread(os.getcwd() + r\"/Test_Images/Test_Image_7.jpg\")\n",
    "image = cv2.imread(os.getcwd() + r\"/Balanced_Dataset/Correct_Mask/00041_Mask.jpg\")\n",
    "# print(image.shape)\n",
    "\n",
    "# Perform rescale of images if needed, comment below to remove rescaling \n",
    "scale_percent = 60 # percent of original size\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# # Include border for if necessary \n",
    "# colour = [255,255,255]\n",
    "# image= cv2.copyMakeBorder(image.copy(),100,100,75,75,cv2.BORDER_CONSTANT,value=colour)\n",
    "\n",
    "# resize image\n",
    "image = cv2.resize(cv2.resize(image, (300, 300)), dim, interpolation = cv2.INTER_AREA)\n",
    "(h,w) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BlobFromImage to feed forward the image into the face detector to detect faces\n",
    "blob = cv2.dnn.blobFromImage(image,1.0, (300,300), (104.0, 177.0, 123.0),crop=False)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# for faces found in the images\n",
    "for i in range(0,detections.shape[2]):\n",
    "    confidence = detections[0,0,i,2]\n",
    "    \n",
    "    # if the confidence of the faces found is greater than 0.5, \n",
    "    # perform bounding boxes and include probability of 3 different classes \n",
    "    # Mask, No Mask, or Incorrect Mask\n",
    "    if confidence>0.5:\n",
    "\n",
    "        box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (startX, startY, endX, endY) = box.astype('int')\n",
    "        \n",
    "        # ensure the bounding boxes fall wihtin the dimensions of the frame\n",
    "        (startX, startY) = (max(0,startX), max(0,startY))\n",
    "        (endX, endY) = (min(w-1,endX), min(h-1,endY))\n",
    "        \n",
    "        # extract the face Region of Interest, convert it from BGR to RGB channel\n",
    "        # resize it to 224, 224 because our model are using Tensor Input of size 224x224\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        \n",
    "        # cvtc - convert colour\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224,224))\n",
    "        \n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        (Corret_Mask, Incorrect_Mask_Chin, Incorrect_Mask_Mouth_Chin, Incorrect_Mask_Nose_Mouth, No_Mask) = model.predict(face)[0]\n",
    "\n",
    "        # define the class label and color for the bounding boxes and text\n",
    "        # in our project we are using Mask, No, Mask and Incorrect Mask\n",
    "        index = (Corret_Mask, Incorrect_Mask_Chin, Incorrect_Mask_Mouth_Chin, Incorrect_Mask_Nose_Mouth, No_Mask).index(max(Corret_Mask, Incorrect_Mask_Chin, Incorrect_Mask_Mouth_Chin, Incorrect_Mask_Nose_Mouth, No_Mask))\n",
    "        if index==0:\n",
    "            label = \"Mask \"\n",
    "            color = (0,255,0)\n",
    "        elif index==1:\n",
    "            label = \"Incorrect Mask(Uncovered Nose Mouth)\"\n",
    "            color = (0, 165, 255)\n",
    "        elif index==2:\n",
    "            label = \"Incorrect Mask(Uncovered Nose)\"\n",
    "            color = (0, 165, 255)\n",
    "        elif index==3:\n",
    "            label = \"Incorrect Mask(Uncovered Chin)\"\n",
    "            color = (0, 165, 255)\n",
    "        elif index==4:\n",
    "            label = \"No mask \"\n",
    "            color = (0,0,255)\n",
    "        \n",
    "        # include probability and label for bounding boxes\n",
    "        label = label + \"{prob}\".format(prob = round(max(Corret_Mask, Incorrect_Mask_Chin, Incorrect_Mask_Mouth_Chin, Incorrect_Mask_Nose_Mouth, No_Mask)*100, 2))\n",
    "        \n",
    "        # put the text and rectange in the image\n",
    "        cv2.putText(image, label, (startX,endY-10),cv2.FONT_HERSHEY_SIMPLEX, 0.45,color,2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX,endY),color,2)\n",
    "\n",
    "        \n",
    "# show the image, until user press 0 or e\n",
    "# xit the window\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c386e288d62b13b36758c4ab83d0dcd67e9cba2429ce0677652c4fb189e44d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('.faceMaskvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
